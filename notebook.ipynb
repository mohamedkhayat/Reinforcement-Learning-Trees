{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TURN TO ENGLISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet : Réimplémentation et Amélioration de l'algorithme RLT (Reinforcement Learning Trees)\n",
    "\n",
    "**Objectif :** Ce notebook structure le projet de réimplémentation en Python de l'algorithme RLT.\n",
    "\n",
    "**Auteurs :** Kousay Najar, Hamza Farhani, Taoufik Krid, Wiem Ben M'Sahel, Rawen Mezzi, Mohamed Khayat\n",
    "\n",
    "**Date :** 11/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 : Compréhension du Métier (Business Understanding)\n",
    "\n",
    "Cette phase a pour but de définir les objectifs du point de vue du métier et de les traduire en un problème de data science bien défini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement, etude de l'existant et limitations, definir strategie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectifs Métier (Business Objectives - BOs)\n",
    "Les BOs décrivent la valeur ajoutée attendue d'un point de vue non technique.\n",
    "\n",
    "- **BO1 :  Reimplementer la strategie.** definire strategie (RLT)\n",
    "\n",
    "- **BO 2 : Comparer les solutions classiques et notre solution.** \n",
    "\n",
    "- **BO3 : Rendre les décisions de la strategie explicables .** \n",
    "\n",
    "- **BO4 : Optimiser la strategie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Objectifs Data Science (Data Science Objectives - DSOs)\n",
    "Les DSOs sont les objectifs techniques qui, une fois atteints, permettront de réaliser les BOs.\n",
    "\n",
    "- **DSO1 : Implémenter l'algorithme Reinforcement Learning Trees (RLT).** \n",
    "\n",
    "- **DSO2 : Effectuer une etude comparative entre le modele RLT et les methodes classiques.** \n",
    "\n",
    "- **DSO3 : Expliquer les predictions du modele en utilisant les methodes XAI.** \n",
    "\n",
    "- **DSO4 : Optimiser le modele RLT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 : Compréhension des Données (Data Understanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "import data_understanding\n",
    "import importlib\n",
    "importlib.reload(data_understanding)\n",
    "qual_variables, quant_variables = data_understanding.understand_data(\"breast_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Diagnosis']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radius1',\n",
       " 'texture1',\n",
       " 'perimeter1',\n",
       " 'area1',\n",
       " 'smoothness1',\n",
       " 'compactness1',\n",
       " 'concavity1',\n",
       " 'concave_points1',\n",
       " 'symmetry1',\n",
       " 'fractal_dimension1',\n",
       " 'radius2',\n",
       " 'texture2',\n",
       " 'perimeter2',\n",
       " 'area2',\n",
       " 'smoothness2',\n",
       " 'compactness2',\n",
       " 'concavity2',\n",
       " 'concave_points2',\n",
       " 'symmetry2',\n",
       " 'fractal_dimension2',\n",
       " 'radius3',\n",
       " 'texture3',\n",
       " 'perimeter3',\n",
       " 'area3',\n",
       " 'smoothness3',\n",
       " 'compactness3',\n",
       " 'concavity3',\n",
       " 'concave_points3',\n",
       " 'symmetry3',\n",
       " 'fractal_dimension3']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 : Préparation des Données (Data Preparation)\n",
    "\n",
    "La préparation consistera principalement à diviser nos jeux de données synthétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4 : Modélisation (Modeling)\n",
    "\n",
    "Cette phase est le cœur du projet. Nous implémentons RLT et ajoutons les extensions requises par DSO2 (modèles embarqués variés) et DSO3 (explicabilité)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BO 1 : data simulées \n",
    "# BO 2 : datak ol\n",
    "# BO 3 : qlq exemples \n",
    "# BO 4 : data kol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSO1: Re-implementing the Strategy (RLT)\n",
    "\n",
    "**Objective:** To build and validate the RLT model by reproducing the paper's experiments on the four controlled, simulated scenarios.\n",
    "\n",
    "| Model | Dataset(s) for Development | Variables Involved | Key Parameters / Hyperparameters to Implement |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **RLT (Reinforcement Learning Trees)** | **Simulated Scenarios 1-4** | **Data is programmatically generated for each scenario:**<br>- **Scenario 1 (Classification):** Signal from `X(1)` & `X(2)`; other `p-2` variables are independent noise.<br>- **Scenario 2 (Non-linear):** Non-linear signal from `X(1)` & `X(2)`; other `p-2` variables are independent noise.<br>- **Scenario 3 (Correlated):** Interaction signal from `X(50)`, `X(100)`, `X(150)`, `X(200)`; other variables are strongly correlated noise.<br>- **Scenario 4 (Linear):** Linear signal from `X(50)`, `X(100)`, `X(150)`; other variables are correlated noise.<br><br>*For all scenarios, total dimension `p` is tested at 200, 500, and 1000.* | - `M` (number of trees) = 100<br>- `nmin` = n^(¹/³)<br>- **Embedded model logic** (Extremely Randomized Trees)<br>- **Muting mechanism** (0%, 50%, 80%)<br>- **Linear combination `k` mechanism** (for k=1, 2, 5) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSO2: Comparing Classical Solutions with Our Solution\n",
    "\n",
    "**Objective:** To conduct a rigorous benchmark on all 10 real-world datasets, comparing the performance and computational efficiency of the re-implemented RLT against standard, high-performing tree-based models.\n",
    "\n",
    "| Model | Dataset(s) for Comparison | Variables Involved | Hyperparameter Search Space | Execution Time |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **RLT (Our Solution)** | **All 10 real datasets** | **For each dataset:**<br>1. Select numeric features only.<br>2. Standardize them (mean=0, var=1).<br>3. Add noisy covariates to reach a total of **p=500** features. | - `k` (linear combination size) in<br>- `muting_rate` in [0, 0.5, 0.8]<br>- `nmin` set to n¹/³ | **Measure and compare:**<br>1. Total training time.<br>2. Prediction time on the test set.<br>|\n",
    "| **Random Forests (RF)** | All 10 real datasets | *Identical data pipeline as RLT* | - `ntrees` in<br>- `mtry` (features per split) in [√p, p/3, p]<br>- `nodesize` (min leaf size) in [2, n¹/³] | **Measure and compare:**<br>1. Total training time.<br>2. Prediction time on the test set.<br>|\n",
    "| **Gradient Boosting (GBM)** | All 10 real datasets | *Identical data pipeline as RLT* | - `ntrees` (boosting rounds) in (use early stopping)<br>- `learning_rate` in [0.01, 0.05, 0.1]<br>- `interaction.depth` in<br>- `n.minobsinnode` in [5, 10, n¹/³] | **Measure and compare:**<br>1. Total training time.<br>2. Prediction time on the test set.<br>|\n",
    "| **XGBoost** | All 10 real datasets | *Identical data pipeline as RLT* | - `n_estimators` in (use early stopping)<br>- `learning_rate` in [0.01, 0.05, 0.1]<br>- `max_depth` in<br>- `subsample` in [0.7, 0.8, 0.9]<br>- `colsample_bytree` in [0.7, 0.8, 0.9] | **Measure and compare:**<br>1. Total training time.<br>2. Prediction time on the test set.<br>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSO3: Making the Strategy's Decisions Explainable\n",
    "\n",
    "**Objective:** To diagnose and understand the behavior of the RLT model by applying global and local explainability techniques, and comparing its decision-making process to that of a standard Random Forest.\n",
    "\n",
    "| Model | Explainability Technique | Dataset(s) for Explainability | Goal of the Technique |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **RLT** & **Random Forest (RF)** | **Global Feature Importance (VIM)** | **Choose 2 contrasting datasets:**<br>1. Where RLT excelled (e.g., `concrete`).<br>2. Where RLT was less dominant (e.g., `Boston housing`). | To identify which of the 500 features the model considers most predictive *overall*, across the entire dataset. |\n",
    "| **RLT** | **LIME (Local Explanations)** | Same two datasets. | To explain *why the model made a specific prediction for a single instance (row)*, providing local, case-by-case insight. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSO4: Proposing and Testing Our Own Improvement\n",
    "\n",
    "**Objective:** To validate if our proposed modifications to the RLT algorithm yield a statistically significant improvement in performance or efficiency over the original implementation.\n",
    "\n",
    "| Model | Dataset(s) for Testing | Variables Involved | Key Parameters / Hyperparameters to Test |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **RLT (Baseline)** | **All 10 real datasets** | **Identical pipeline for both models:**<br>1. Select numeric features only.<br>2. Standardize them (mean=0, var=1).<br>3. Add noisy covariates to reach **p=500**. | **Original paper's configuration:**<br>- `k` in<br>- `muting_rate` in [0, 0.5, 0.8]<br>- `embedded_model` = 'ExtremelyRandomizedTrees' |\n",
    "| **Improved RLT** | **All 10 real datasets** | *Identical data pipeline as the baseline for a fair comparison.* | **Test one or more proposed improvements:**<br>- **Idea 1:** Change `embedded_model` to 'LightGBM'.<br>- **Idea 2:** Change `muting_strategy` to 'adaptive_quantile'.<br>- **Idea 3:** Change `linear_combination_method` to 'ridge_weighted'.<br><br>*(All other parameters remain identical to the baseline)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5 : Évaluation (Evaluation)\n",
    "\n",
    "Nous validons ici les trois DSOs de manière distincte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Validation DSO1 : Reproduction RLT Standard ===\n",
    "# Entraîner RLT (mode standard) sur 'Checkerboard' et comparer avec RandomForest sklearn.\n",
    "# Critère : RLT doit avoir une accuracy significativement supérieure grâce au 'combsplit'.\n",
    "\n",
    "# === Validation DSO2 : Benchmarking des Modèles Embarqués ===\n",
    "# Comparer RLT_Standard (embedded='rf') vs RLT_Boosted (embedded='lightgbm').\n",
    "# Mesurer : Temps d'entraînement et Précision/MSE sur les données bruitées.\n",
    "# Critère : RLT_Boosted doit montrer un gain de performance ou de vitesse.\n",
    "\n",
    "# === Validation DSO3 : Qualité de l'Explicabilité ===\n",
    "# Utiliser .explain() sur le jeu de données bruité.\n",
    "# Vérifier si la heatmap générée attribue une importance proche de 0 aux variables de bruit.\n",
    "# Visualiser une 'Feature Heatmap' pour quelques prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6 : Déploiement (Deployment)\n",
    "\n",
    "Préparation du modèle pour l'intégration, en mettant l'accent sur l'explicabilité (BO3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Sauvegarde du Modèle Optimisé\n",
    "Sauvegarder la meilleure version du modèle (probablement celle issue de DSO2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Interface Streamlit (avec XAI)\n",
    "**Objectif :** Démonstrateur interactif incluant la transparence.\n",
    "\n",
    "**Fonctionnalités :**\n",
    "- Inputs utilisateur.\n",
    "- Affichage Prédiction.\n",
    "- **Feature Heatmap (BO3) :** Afficher graphiquement quelles variables ont poussé la décision (output de `.explain()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 API FastAPI\n",
    "**Objectif :** Intégration système.\n",
    "\n",
    "**Endpoint :** `POST /predict`\n",
    "- **Input :** Données JSON.\n",
    "- **Output :** `{\"prediction\": value, \"explanation\": {feature_contributions}}`\n",
    "- L'API retourne non seulement le résultat mais aussi le \"pourquoi\" (BO3)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
